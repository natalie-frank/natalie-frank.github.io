---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
{% include base_path %}
**On the Existence of the Adversarial Bayes Classifier**,  Authors: Pranjal Awasthi, Natalie Frank, Mehryar Mohri. <i>Submitted to NeurIps</i>.<br> 
We study the existence of minimizers to the adversarial classification loss.

**Calibration and Consistency of Adversarial Surrogate Losses**,  Authors: Pranjal Awasthi, Natalie Frank, Anqi Mao, Mehryar Mohri, Yutao Zhong. <i>Submitted to NeurIps</i>.<br> 
This paper studies statistical consistency and calibration in the adversarial setting. We show that no continuous surrogate loss is statistically consistent in the adversarial setting when learning over a well-motivated linear function class. Furthermore, supremum based convex losses are not $H$-calibrated for typical linear and neural net function classes. Lastly, we find distributional assumptions under which some surrogate losses are statistically consistent for linear function classes and one-layer neural networks. 

**Adversarial Learning Guarantees for Linear Hypotheses Sets and Neural Networks**,  Authors: Pranjal Awasthi, Natalie Frank, Mehryar Mohri. <i>ICML</i>, 2020. [link](http://proceedings.mlr.press/v119/awasthi20a.html)<br>
Consider perturbations measured in $\ell_r$ norm. We give bounds on the adversarial Rademacher complexity of linear classes, a single ReLU unit, feed-forward neural networks.

**The Frog Model on Trees with Drift**,  Authors: Erin Beckman, Natalie Frank, Yufeng Jiang, Matthew Junge, Si Tang. <i>Electronic Communications in Probability</i>, 2019. [link](https://projecteuclid.org/journals/electronic-communications-in-probability/volume-24/issue-none/The-frog-model-on-trees-with-drift/10.1214/19-ECP235.full)<br>
Consider the one-per-cite frog model on a $d$-ary tree with drift towards the root. We show that for any $d$, the frog model is recurrent with drift larger than or equal to $0.4155$. 
  
# Expository Notes
  
**On the Rademacher Complexity of Linear Hypothesis Sets**, Authors: Pranjal Awasthi, Natalie Frank, Mehryar Mohri. 2020. [link](https://arxiv.org/abs/2007.11045)<br>
We give upper and lower bounds on the empirical Rademacher complexity of the linear hypothesis classes with weight factors bounded in $\ell_p$ norm. We show that our bounds improve upon existing bounds, which were known only for $1\leq p \leq 2$.
